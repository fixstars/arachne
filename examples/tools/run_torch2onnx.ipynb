{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Torch2ONNX from Arachne\n",
    "\n",
    "Here, we explain how to use the Torch2ONNX tool from Arachne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Model\n",
    "\n",
    "First, we have to prepare a model to be used in this tutorial.\n",
    "Here, we will use a pre-trained model of the ResNet-18 from `torchvision.models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "torch.save(resnet18, f=\"/tmp/resnet18.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Torch2ONNX from Arachne\n",
    "\n",
    "Now, let's convert the model into an ONNX model by Arachne.\n",
    "To use the tool, we have to specify `+tools=torch2onnx` to `arachne.driver.cli`.\n",
    "Available options can be seen by adding `--help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli is powered by Hydra.\n",
      "\n",
      "== Configuration groups ==\n",
      "Compose your configuration from those groups (group=option)\n",
      "\n",
      "tools: onnx_simplifier, onnx_tf, openvino2tf, openvino_mo, tflite_converter, tftrt, torch2onnx, torch2trt, tvm\n",
      "tvm_target: dgx-1, dgx-s, jetson-nano, jetson-xavier-nx, rasp4b64\n",
      "\n",
      "\n",
      "== Config ==\n",
      "Override anything in the config (foo.bar=value)\n",
      "\n",
      "model_file: null\n",
      "model_dir: null\n",
      "model_spec_file: null\n",
      "output_path: ???\n",
      "tools:\n",
      "  torch2onnx:\n",
      "    export_params: true\n",
      "    verbose: false\n",
      "    training: 0\n",
      "    operator_export_type: null\n",
      "    opset_version: 9\n",
      "    do_constant_folding: false\n",
      "    dynamic_axes: null\n",
      "    keep_initializers_as_inputs: null\n",
      "    custom_opsets: null\n",
      "\n",
      "\n",
      "Powered by Hydra (https://hydra.cc)\n",
      "Use --hydra-help to view Hydra specific help\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m arachne.driver.cli +tools=torch2onnx --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing the Pytorch model and it's tensor specification, the tool will covert the model into an ONNX model by the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yml = \"\"\"\n",
    "inputs:\n",
    "  - dtype: float32\n",
    "    name: input\n",
    "    shape:\n",
    "    - 1\n",
    "    - 3\n",
    "    - 224\n",
    "    - 224\n",
    "outputs:\n",
    "  - dtype: float32\n",
    "    name: output\n",
    "    shape:\n",
    "    - 1\n",
    "    - 16\n",
    "    - 224\n",
    "    - 224\n",
    "\"\"\"\n",
    "open(\"/tmp/resnet18.yaml\", \"w\").write(yml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python -m arachne.driver.cli +tools=torch2onnx model_file=/tmp/resnet18.pt model_spec_file=/tmp/resnet18.yaml output_path=/tmp/output.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Torch2ONNX from Arachne Python Interface\n",
    "\n",
    "The following code shows an example of using the tool from Arachne Python interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arachne.data import ModelSpec, TensorSpec\n",
    "from arachne.utils.model_utils import init_from_file, save_model\n",
    "from arachne.tools.torch2onnx import Torch2ONNX, Torch2ONNXConfig\n",
    "\n",
    "model_file_path = \"/tmp/resnet18.pt\"\n",
    "input = init_from_file(model_file_path)\n",
    "spec = ModelSpec(\n",
    "    inputs=[TensorSpec(name=\"input0\", shape=[1, 3, 224, 224], dtype=\"float32\")],\n",
    "    outputs=[TensorSpec(name=\"output0\", shape=[1, 1000], dtype=\"float32\")],\n",
    ")\n",
    "input.spec = spec\n",
    "\n",
    "cfg = Torch2ONNXConfig()\n",
    "\n",
    "output = Torch2ONNX.run(input, cfg)\n",
    "\n",
    "save_model(model=output, output_path=\"/tmp/output.tar\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fafabb367c689809e9098d9e06eeddad4dedf0748e439d9c922f0a4231fa874d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
