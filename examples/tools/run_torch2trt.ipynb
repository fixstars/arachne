{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Torch2TRT from Arachne\n",
    "\n",
    "The [torch2trt](https://github.com/NVIDIA-AI-IOT/torch2trt>) is a PyTorch to TensorRT converter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Model\n",
    "\n",
    "First, we have to prepare a model to be used in this tutorial.\n",
    "Here, we will use a pre-trained model of the ResNet-18 from `torchvision.models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "resnet18 = torchvision.models.resnet18(pretrained=True)\n",
    "torch.save(resnet18, f=\"/tmp/resnet18.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Torch2TRT from Arachne\n",
    "\n",
    "Now, let's optimize the model with the torch2trt by Arachne.\n",
    "To use the tool, we have to specify `+tools=torch2trt` to `arachne.driver.cli`.\n",
    "Available options can be seen by adding `--help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cli is powered by Hydra.\n",
      "\n",
      "== Configuration groups ==\n",
      "Compose your configuration from those groups (group=option)\n",
      "\n",
      "tools: onnx_simplifier, onnx_tf, openvino2tf, openvino_mo, tflite_converter, tftrt, torch2onnx, torch2trt, tvm\n",
      "tvm_target: dgx-1, dgx-s, jetson-nano, jetson-xavier-nx, rasp4b64\n",
      "\n",
      "\n",
      "== Config ==\n",
      "Override anything in the config (foo.bar=value)\n",
      "\n",
      "input: ???\n",
      "input_spec: null\n",
      "output: ???\n",
      "tools:\n",
      "  torch2trt:\n",
      "    max_batch_size: 1\n",
      "    fp16_mode: false\n",
      "    max_workspace_size: 33554432\n",
      "    strict_type_constraints: false\n",
      "    keep_network: true\n",
      "    int8_mode: false\n",
      "    int8_calib_dataset: null\n",
      "    int8_calib_algorithm: DEFAULT\n",
      "    int8_calib_batch_size: 1\n",
      "    use_onnx: false\n",
      "\n",
      "\n",
      "Powered by Hydra (https://hydra.cc)\n",
      "Use --hydra-help to view Hydra specific help\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "python -m arachne.driver.cli +tools=torch2trt --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize with FP32 precision\n",
    "\n",
    "First, we will start with the simplest case.\n",
    "You can optimize a TF model with FP32 precision by the following command.\n",
    "Note that, the Pytorch model does not include the information about tensor specification.\n",
    "So, we need to pass the YAML file indicating the shape information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "  - dtype: float32\n",
      "    name: input0\n",
      "    shape:\n",
      "    - 1\n",
      "    - 3\n",
      "    - 224\n",
      "    - 224\n",
      "outputs:\n",
      "  - dtype: float32\n",
      "    name: output0\n",
      "    shape:\n",
      "    - 1\n",
      "    - 1000"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "cat /tmp/resnet18.yaml\n",
    "\n",
    "python -m arachne.driver.cli +tools=torch2trt input=/tmp/resnet18.pt input_spec=/tmp/resnet18.yaml output=/tmp/output.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize with FP16 precision\n",
    "\n",
    "To optimize with FP16 precision, set `true` to the `tools.torch2trt.fp16_mode` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python -m arachne.driver.cli +tools=torch2trt input=/tmp/resnet18.pt input_spec=/tmp/resnet18.yaml output=/tmp/output.tar tools.torch2trt.fp16_mode=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize with INT8 Precision\n",
    "\n",
    "To convert with INT8 precision, we need calibrate or estimate the range of all floating-point tensors in the model.\n",
    "We provide an interface to feed the dataset to be used in the calibration.\n",
    "First, we have to prepare a NPY file that contains a list of `np.ndarray` which is a dataset used for calibration.\n",
    "Here, we use a dummy dataset for explanation because the IMAGENET dataset requires manual setups for users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "datasets = []\n",
    "shape = [1, 3, 224, 224]\n",
    "dtype = \"float32\"\n",
    "for _ in range(100):\n",
    "    datasets.append(np.random.rand(*shape).astype(np.dtype(dtype)))  # type: ignore\n",
    "\n",
    "np.save(\"/tmp/calib_dataset.npy\", datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, specify `true` to the `tools.torch2trt.int8_mode` option and pass the NPY file to the `tools.torch2trt.int8_calib_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python -m arachne.driver.cli +tools=torch2trt input=/tmp/resnet18.pt input_spec=/tmp/resnet18.yaml output=/tmp/output.tar \\\n",
    "    tools.torch2trt.int8_mode=true tools.torch2trt.int8_calib_dataset=/tmp/calib_dataset.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Torch2TRT from Arachne Python Interface\n",
    "\n",
    "The following code shows an example of using the tool from Arachne Python interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arachne.data import Model, ModelSpec, TensorSpec\n",
    "from arachne.utils.model_utils import save_model\n",
    "from arachne.tools.torch2trt import Torch2TRT, Torch2TRTConfig\n",
    "\n",
    "model_file_path = \"/tmp/resnet18.pt\"\n",
    "spec = ModelSpec(\n",
    "    inputs=[TensorSpec(name=\"input0\", shape=[1, 3, 224, 224], dtype=\"float32\")],\n",
    "    outputs=[TensorSpec(name=\"output0\", shape=[1, 1000], dtype=\"float32\")],\n",
    ")\n",
    "input = Model(path=model_file_path, spec=spec)\n",
    "\n",
    "cfg = Torch2TRTConfig()\n",
    "\n",
    "# cfg.fp16_mode = True\n",
    "\n",
    "output = Torch2TRT.run(input, cfg)\n",
    "\n",
    "save_model(model=output, output_path=\"/tmp/output.tar\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fafabb367c689809e9098d9e06eeddad4dedf0748e439d9c922f0a4231fa874d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
